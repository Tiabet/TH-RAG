import os, openai, json, sys, time
from typing import List, Dict
from pathlib import Path
from dotenv import load_dotenv

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ë¥¼ ê²½ë¡œì— ì¶”ê°€
PROJECT_ROOT = Path(__file__).parent.parent
sys.path.insert(0, str(PROJECT_ROOT))

from Retriever import Retriever
from prompt.answer_short import ANSWER_PROMPT

# â”€â”€ í™˜ê²½ë³€ìˆ˜ ë° ê²½ë¡œ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
load_dotenv()
import sys
from pathlib import Path

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ ì„¤ì •
PROJECT_ROOT = Path(__file__).parent.parent
sys.path.insert(0, str(PROJECT_ROOT))

# ì„¤ì • import
from config import get_config
config = get_config()

OPENAI_API_KEY = config.openai_api_key
if not OPENAI_API_KEY:
    raise ValueError("OPENAI_API_KEY env var required.")

EMBED_MODEL = config.embed_model
CHAT_MODEL  = config.chat_model

class GraphRAG:
    def __init__(self,
        dataset_name: str = None,
        gexf_path: str = None,
        json_path: str = None,
        kv_json_path: str = None,
        index_path: str = None,
        payload_path: str = None,
        embed_model: str = EMBED_MODEL,
        chat_model: str = CHAT_MODEL,
    ):
        # ì„¤ì • ê°ì²´ ìƒì„±
        if dataset_name:
            config = get_config(dataset_name)
            self.gexf_path = gexf_path or str(config.get_graph_gexf_file())
            self.json_path = json_path or str(config.get_graph_json_file())
            self.kv_json_path = kv_json_path or str(config.get_kv_store_file())
            self.index_path = index_path or str(config.get_edge_index_file())
            self.payload_path = payload_path or str(config.get_edge_payload_file())
        else:
            # ê¸°ë³¸ê°’ ì„¤ì • (í˜¸í™˜ì„±ì„ ìœ„í•´)
            self.gexf_path = gexf_path or "hotpotQA/graph_v1.gexf"
            self.json_path = json_path or "hotpotQA/graph_v1.json"
            self.kv_json_path = kv_json_path or "hotpotQA/kv_store_text_chunks.json"
            self.index_path = index_path or "hotpotQA/edge_index_v1.faiss"
            self.payload_path = payload_path or "hotpotQA/edge_payloads_v1.npy"
        
        self.embed_model = embed_model
        self.chat_model = chat_model
        self.client = openai.OpenAI(api_key=OPENAI_API_KEY)

        # kv-store json ë¡œë”© (chunk_id â†’ ë³¸ë¬¸)
        with open(self.kv_json_path, encoding="utf-8") as f:
            kv_data = json.load(f)
        self.chunk_map: Dict[str, str] = {
            chunk_id: obj["content"] for chunk_id, obj in kv_data.items()
        }

        # ì²­í¬â€‘ê¸°ë°˜ Retriever
        self.retriever = Retriever(
            gexf_path       = self.gexf_path,
            json_path       = self.json_path,
            kv_json_path    = self.kv_json_path,
            index_path      = self.index_path,
            payload_path    = self.payload_path,
            embedding_model = embed_model,
            openai_api_key  = OPENAI_API_KEY,
            client          = self.client,
        )

        self.chat_model = chat_model

    def compose_context(self, chunk_ids: List[str], edges_meta: List[Dict]) -> str:
        """
        chunk_ids : top_k2ê°œì˜ chunk-id
        edges_meta : top_k1ê°œì˜ ì „ì²´ ì—£ì§€ ì •ë³´
        """
        parts: List[str] = []

        # 1) ì²­í¬ ë³¸ë¬¸ (chunk-id â†’ ì‹¤ì œ í…ìŠ¤íŠ¸)
        for i, cid in enumerate(chunk_ids, 1):
            text = self.chunk_map.get(cid, "(missing)")
            parts.append(f"[Chunk {i}] {text}")

        # 2) ì „ì²´ edge ì •ë³´
        for i, hit in enumerate(edges_meta, 1):
            source = hit.get("source", "?")
            label  = hit.get("label", "?")
            target = hit.get("target", "?")
            # score  = hit.get("score", 0.0)
            # rank   = hit.get("rank", "?")
            sent   = hit.get("sentence", "")
            # cid  = hit.get("chunk_id", "?")  # í•„ìš”ì‹œ í¬í•¨ ê°€ëŠ¥

            parts.append(
                # f"(Edge {i} | rank={rank} score={score:.3f})\n"
                f"[{source}] --{label}â†’ [{target}]\n"
                f"{sent}"
            )

        return "\n".join(parts)

    # ------------------------------------------------------------------
    def answer(self, query: str, top_k1: int = 50, top_k2: int = 10) -> str:
        # Retriever ì‹¤í–‰ â†’ chunk-ids + edges
        start_time = time.time()
        out = self.retriever.retrieve(query, top_k1=top_k1, top_k2=top_k2)
        end_time = time.time()
        spent_time = end_time - start_time

        chunk_ids: List[str] = out.get("chunks", [])
        edges_meta: List[Dict] = out.get("edges", [])

        chunk_ids: List[str] = out.get("chunks", [])
        edges_meta: List[Dict] = out.get("edges", [])

        # âœ… sentenceë“¤ì´ ë“¤ì–´ìˆë˜ ëª¨ë“  chunk-id ìˆ˜ì§‘
        all_sentence_chunk_ids = []
        seen_chunk_ids = set()
        for edge in edges_meta:
            raw_id = edge.get("chunk_id")
            chunk_id = None
            if isinstance(raw_id, int):
                if 0 <= raw_id < len(self.retriever.chunk_id_list):
                    chunk_id = self.retriever.chunk_id_list[raw_id]
            elif isinstance(raw_id, str) and raw_id.isdigit():
                idx = int(raw_id)
                if 0 <= idx < len(self.retriever.chunk_id_list):
                    chunk_id = self.retriever.chunk_id_list[idx]
            elif isinstance(raw_id, str) and raw_id.startswith("chunk-"):
                chunk_id = raw_id
            if chunk_id and chunk_id not in seen_chunk_ids:
                all_sentence_chunk_ids.append(chunk_id)
                seen_chunk_ids.add(chunk_id)

        self.last_chunk_ids = chunk_ids  # top-k2
        self.all_sentence_chunk_ids = all_sentence_chunk_ids  # âœ… ìƒˆë¡œ ì¶”ê°€
        
        if not chunk_ids:
            return "ì£„ì†¡í•©ë‹ˆë‹¤. ê´€ë ¨ ì •ë³´ë¥¼ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤."

        # ì»¨í…ìŠ¤íŠ¸ ì¡°ë¦½
        context = self.compose_context(chunk_ids, edges_meta)
        prompt  = ANSWER_PROMPT.replace("{question}", query).replace("{context}", context)

        resp = self.client.chat.completions.create(
            model=self.chat_model,
            messages=[
                {"role": "system", "content": "You are a graphâ€‘aware assistant, and an expert that always gives detailed, comprehensive answers."},
                {"role": "user",   "content": prompt},
            ],
            temperature=0.0,
            response_format={"type": "text"},
        )
        return resp.choices[0].message.content.strip(), spent_time, context

# â”€â”€ ì˜ˆì‹œ ì‹¤í–‰ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
if __name__ == "__main__":
    # í…ŒìŠ¤íŠ¸ìš© ì˜ˆì œ
    import json, numpy as np, faiss, os
    
    # ê¸°ë³¸ ì„¤ì •ìœ¼ë¡œ í…ŒìŠ¤íŠ¸
    config = get_config("hotpotQA")  # ê¸°ë³¸ ë°ì´í„°ì…‹
    
    kv_json_path = str(config.get_kv_store_file())
    payload_path = str(config.get_edge_payload_file())
    index_path = str(config.get_edge_index_file())
    
    if os.path.exists(kv_json_path):
        with open(kv_json_path, encoding="utf-8") as f:
            kv_data = json.load(f)
        print("ğŸ“ kvâ€‘store chunks :", len(kv_data))
    
    if os.path.exists(payload_path):
        payload = np.load(payload_path, allow_pickle=True)
        print("ğŸ“¦ payload entries:", len(payload))
    
    if os.path.exists(index_path):
        index = faiss.read_index(index_path)
        print("ğŸ” faiss index    :", index.ntotal)
        
        rag = GraphRAG(dataset_name="hotpotQA")
        q = "Which OpenAI figure rose with ChatGPT, promoted AI agents, and faced board controversy per Fortune and TechCrunch?"
        ans = rag.answer(q, top_k1=50, top_k2=5)
        print("\n=== Answer ===")
        print(ans)
    else:
        print("âŒ Index files not found. Please run indexing first.")