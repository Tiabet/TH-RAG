# save_chunks.py
# --- í•˜ë“œì½”ë”© ì„¤ì • ---
TXT_PATH   = "MultihopRAG/contexts.txt"   # ì›ë³¸ í…ìŠ¤íŠ¸
OUT_PATH   = "MultihopRAG/chunks_v1.txt"                 # ì²­í¬ ì €ì¥ íŒŒì¼
MODEL_NAME = "gpt-4o-mini"                            # tiktoken ëª¨ë¸
MAX_TOKENS = 1200                                     # ì²­í¬ í† í° ìˆ˜
OVERLAP    = 100                                      # ì²­í¬ ê°„ ê²¹ì¹¨ í† í° ìˆ˜
# ----------------------

from pathlib import Path
import tiktoken

# ì²­í¬ í•¨ìˆ˜
def chunk_text(text: str, max_tokens: int, overlap: int, model: str):
    enc = tiktoken.encoding_for_model(model)
    tokens = enc.encode(text)
    chunks, start = [], 0
    while start < len(tokens):
        chunk_tokens = tokens[start : start + max_tokens]
        chunks.append(enc.decode(chunk_tokens))
        start += max_tokens - overlap
    return chunks

# 1) ì›ë³¸ ì½ê¸°
full_text = Path(TXT_PATH).read_text(encoding="utf-8")

# 2) ì²­í‚¹
chunks = chunk_text(full_text, MAX_TOKENS, OVERLAP, MODEL_NAME)
print(f"âœ… ì²­í¬ {len(chunks)}ê°œ ìƒì„±")

# 3) ì €ì¥ (í•œ ì¤„ = í•œ ì²­í¬, ì¤„ë°”ê¿ˆ ì œê±°)
with Path(OUT_PATH).open("w", encoding="utf-8") as f:
    for ch in chunks:
        f.write(ch.replace("\n", " ").strip() + "\n")

print(f"ğŸ’¾ ì €ì¥ ì™„ë£Œ â†’ {OUT_PATH}")
