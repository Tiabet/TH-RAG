from pathlib import Path
import tiktoken
import json
import hashlib

# íŒŒì¼ ê²½ë¡œ
TXT_PATH = Path("UltraDomain/Mix/contexts.txt")
OUT_JSON_PATH = Path("UltraDomain/Mix/kv_store_text_chunks.json")

# ì²­í¬ ì„¤ì •
MODEL_NAME = "gpt-4o-mini"
MAX_TOKENS = 1200
OVERLAP = 100

# í…ìŠ¤íŠ¸ â†’ ì²­í¬ ë¦¬ìŠ¤íŠ¸
def chunk_text(text: str, max_tokens: int, overlap: int, model: str):
    enc = tiktoken.encoding_for_model(model)
    tokens = enc.encode(text)
    chunks, start = [], 0
    while start < len(tokens):
        chunk_tokens = tokens[start : start + max_tokens]
        chunks.append(enc.decode(chunk_tokens))
        start += max_tokens - overlap
    return chunks

# 1) ì „ì²´ í…ìŠ¤íŠ¸ ë¶ˆëŸ¬ì˜¤ê¸°
full_text = TXT_PATH.read_text(encoding="utf-8")

# 2) ì²­í‚¹
chunks = chunk_text(full_text, MAX_TOKENS, OVERLAP, MODEL_NAME)
print(f"âœ… ì´ {len(chunks)}ê°œì˜ ì²­í¬ ìƒì„± ì™„ë£Œ.")

# 3) kv-store JSON ì €ì¥
kv_data = {}
for i, chunk in enumerate(chunks):
    cleaned = chunk.replace("\n", " ").strip()
    chunk_hash = hashlib.md5(cleaned.encode("utf-8")).hexdigest()
    chunk_id = f"chunk-{chunk_hash}"
    kv_data[chunk_id] = {
        "tokens": len(cleaned.split()),  # ë˜ëŠ” ì‹¤ì œ í† í° ìˆ˜ ì‚¬ìš© ê°€ëŠ¥
        "content": cleaned,
        "chunk_order_index": i,
        "full_doc_id": "doc-from-contexts"
    }

# 4) ì €ì¥
with OUT_JSON_PATH.open("w", encoding="utf-8") as f:
    json.dump(kv_data, f, indent=2, ensure_ascii=False)

print(f"ğŸ’¾ ì €ì¥ ì™„ë£Œ â†’ {OUT_JSON_PATH}")
